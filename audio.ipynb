{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d388e1c-2d62-4ca0-a41e-a2eaff6862c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2296c81c-90a2-49bd-a081-37c4ab08efad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "#### Extracting MFCC's For every audio file\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c701c5a3-0b34-4ba0-9d53-fbdf7c1abde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dataset_path = r'C:\\Users\\HP\\Desktop\\baby_crying\\donateacry_corpus_cleaned_and_updated_data\\hungry'\n",
    "librosa_audio_data,librosa_sample_rate=librosa.load(audio_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "eb16497f-f075-4f9d-a834-c56f9cc8c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(file):\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    \n",
    "    return mfccs_scaled_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "98ccfc32-89a3-49d4-ae65-dad7d020e315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 58.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 63.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 71.56it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 382/382 [00:05<00:00, 72.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 68.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               feature       class\n",
      "0    [-405.876, 27.121643, -42.248203, -0.3469377, ...  belly_pain\n",
      "1    [-383.83685, 38.426846, -19.573414, -8.295806,...  belly_pain\n",
      "2    [-304.17505, 41.778366, -26.64577, -17.834064,...  belly_pain\n",
      "3    [-252.53748, 35.876537, -35.229088, -20.087471...  belly_pain\n",
      "4    [-171.50912, 41.75074, -15.136598, -21.78959, ...  belly_pain\n",
      "..                                                 ...         ...\n",
      "452  [-457.82492, -2.3358393, -21.825369, 20.692574...       tired\n",
      "453  [-299.7658, -22.056196, -54.869995, -10.684994...       tired\n",
      "454  [-212.82039, -33.9803, -79.00461, -15.763538, ...       tired\n",
      "455  [-181.16437, -24.079264, -38.59076, -25.037159...       tired\n",
      "456  [-518.13745, 55.82258, 19.839031, 15.108027, 2...       tired\n",
      "\n",
      "[457 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the path to your audio dataset\n",
    "audio_dataset_path = r'C:\\Users\\HP\\Desktop\\baby_crying\\donateacry_corpus_cleaned_and_updated_data'\n",
    "\n",
    "# Initialize an empty list to store extracted features and labels\n",
    "extracted_features = []\n",
    "\n",
    "# Function to extract features from an audio file (placeholder)\n",
    "def features_extractor(file_name):\n",
    "    # Replace with your actual feature extraction code\n",
    "    y, sr = librosa.load(file_name, sr=None)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    return np.mean(mfccs.T, axis=0)\n",
    "\n",
    "# Iterate through each folder (label) and file\n",
    "for label in os.listdir(audio_dataset_path):\n",
    "    folder_path = os.path.join(audio_dataset_path, label)\n",
    "    if os.path.isdir(folder_path):\n",
    "        for audio_file in tqdm(os.listdir(folder_path)):\n",
    "            file_path = os.path.join(folder_path, audio_file)\n",
    "            if file_path.endswith('.wav'):  # Ensure it's an audio file\n",
    "                data = features_extractor(file_path)\n",
    "                extracted_features.append([data, label])\n",
    "\n",
    "# Convert extracted features and labels to a DataFrame if needed\n",
    "import pandas as pd\n",
    "\n",
    "features_df = pd.DataFrame(extracted_features, columns=['feature', 'class'])\n",
    "\n",
    "# Print the DataFrame or save it to a CSV file\n",
    "print(features_df)\n",
    "# features_df.to_csv('extracted_features.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "dd3ba042-5d9a-4d8c-950b-60f714be84cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-405.876, 27.121643, -42.248203, -0.3469377, ...</td>\n",
       "      <td>belly_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-383.83685, 38.426846, -19.573414, -8.295806,...</td>\n",
       "      <td>belly_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-304.17505, 41.778366, -26.64577, -17.834064,...</td>\n",
       "      <td>belly_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-252.53748, 35.876537, -35.229088, -20.087471...</td>\n",
       "      <td>belly_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-171.50912, 41.75074, -15.136598, -21.78959, ...</td>\n",
       "      <td>belly_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>[-457.82492, -2.3358393, -21.825369, 20.692574...</td>\n",
       "      <td>tired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>[-299.7658, -22.056196, -54.869995, -10.684994...</td>\n",
       "      <td>tired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>[-212.82039, -33.9803, -79.00461, -15.763538, ...</td>\n",
       "      <td>tired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>[-181.16437, -24.079264, -38.59076, -25.037159...</td>\n",
       "      <td>tired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>[-518.13745, 55.82258, 19.839031, 15.108027, 2...</td>\n",
       "      <td>tired</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>457 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               feature       class\n",
       "0    [-405.876, 27.121643, -42.248203, -0.3469377, ...  belly_pain\n",
       "1    [-383.83685, 38.426846, -19.573414, -8.295806,...  belly_pain\n",
       "2    [-304.17505, 41.778366, -26.64577, -17.834064,...  belly_pain\n",
       "3    [-252.53748, 35.876537, -35.229088, -20.087471...  belly_pain\n",
       "4    [-171.50912, 41.75074, -15.136598, -21.78959, ...  belly_pain\n",
       "..                                                 ...         ...\n",
       "452  [-457.82492, -2.3358393, -21.825369, 20.692574...       tired\n",
       "453  [-299.7658, -22.056196, -54.869995, -10.684994...       tired\n",
       "454  [-212.82039, -33.9803, -79.00461, -15.763538, ...       tired\n",
       "455  [-181.16437, -24.079264, -38.59076, -25.037159...       tired\n",
       "456  [-518.13745, 55.82258, 19.839031, 15.108027, 2...       tired\n",
       "\n",
       "[457 rows x 2 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e0b8f51d-2a2d-424f-bc90-9df08994f79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the dataset into independent and dependent dataset\n",
    "X=np.array(features_df['feature'].tolist())\n",
    "y=np.array(features_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "42616a62-eaf3-4264-906c-23baa3a84802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(457, 13)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "319ad853-b848-43d6-b29b-9f11c62f4823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['belly_pain', 'belly_pain', 'belly_pain', 'belly_pain',\n",
       "       'belly_pain', 'belly_pain', 'belly_pain', 'belly_pain',\n",
       "       'belly_pain', 'belly_pain', 'belly_pain', 'belly_pain',\n",
       "       'belly_pain', 'belly_pain', 'belly_pain', 'belly_pain', 'burping',\n",
       "       'burping', 'burping', 'burping', 'burping', 'burping', 'burping',\n",
       "       'burping', 'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'discomfort',\n",
       "       'discomfort', 'discomfort', 'discomfort', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'hungry', 'hungry', 'hungry', 'hungry',\n",
       "       'hungry', 'hungry', 'tired', 'tired', 'tired', 'tired', 'tired',\n",
       "       'tired', 'tired', 'tired', 'tired', 'tired', 'tired', 'tired',\n",
       "       'tired', 'tired', 'tired', 'tired', 'tired', 'tired', 'tired',\n",
       "       'tired', 'tired', 'tired', 'tired', 'tired'], dtype='<U10')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "cdea9125-82a7-4ea6-9b5f-abba217de2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Label Encoder\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d14f510f-ecde-4910-9673-9c641f82fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y=to_categorical(labelencoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ef9be1ea-7a71-4d9e-96ff-9330190d3b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('label_classes.npy', labelencoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3f6cf441-d1d3-4c76-b0f4-c28294d4f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save classes to a pickle file\n",
    "with open('label_classes.pkl', 'wb') as file:\n",
    "    pickle.dump(labelencoder.classes_, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "efdf69e4-0376-4ec1-a73e-a4d8ceb8e73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "19a31e0d-40bf-4d68-bc57-0327ed5b7557",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "25866ec1-9718-4f18-8a27-ff072574b7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.8614853e+01,  1.4083795e+02,  3.6772716e+00, ...,\n",
       "        -9.1676836e+00, -8.6280746e+00, -1.1213494e+01],\n",
       "       [-2.3790605e+02,  3.6274277e+01, -6.8085541e+01, ...,\n",
       "        -1.0337540e+01,  1.5205305e+01,  1.3561142e+01],\n",
       "       [-1.1341600e+02, -1.7937687e+01, -5.2245979e+01, ...,\n",
       "        -1.2297320e+01,  7.0339804e+00,  6.8785353e+00],\n",
       "       ...,\n",
       "       [-3.0176901e+02,  4.2159557e+00, -1.4924260e+01, ...,\n",
       "        -4.6433110e+00, -2.2544725e+00, -4.5861474e-01],\n",
       "       [-2.0864082e+02, -2.8164577e+01, -5.9126392e+01, ...,\n",
       "        -3.4985397e+00,  1.6541507e+00, -7.9785980e-02],\n",
       "       [-2.0229742e+02, -1.0486810e+01, -5.2694508e+01, ...,\n",
       "        -2.8961947e+00,  7.7617645e+00,  2.7590129e+00]], dtype=float32)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "97327ef5-4aa2-4c4a-b09b-a5abb97c8535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "cd0303d4-4c3d-4e8c-bcbf-fd5ace866b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 13)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "0503bac6-147c-4530-8971-a3c788fdff2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92, 13)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2b9fedb1-8c2e-40a6-a997-6ec686112960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 5)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5075163d-4623-44a4-a8c8-ed809356017b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92, 5)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "77a2a0c7-67e3-4781-9c5d-a789c423040c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "379fd8ef-de5a-4136-ae7c-6f51eee0eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c068c5d8-af85-4a85-9234-636720a8e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### No of classes\n",
    "num_labels=y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b13b2793-aab0-4b52-9129-e4bcd7ccd46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(13,), activation='relu'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8f6cffcb-81f2-474e-8d10-52b224367e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,400</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">505</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │           \u001b[38;5;34m1,400\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_20 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │          \u001b[38;5;34m20,200\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_21 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m20,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_22 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m505\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_23 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,205</span> (164.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m42,205\u001b[0m (164.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,205</span> (164.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m42,205\u001b[0m (164.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c4e64463-e1a5-4293-a3b5-f4042dd83fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b5d87bbc-1c75-4eeb-8ae3-b6c07dbc4215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m56s\u001b[0m 5s/step - accuracy: 0.2812 - loss: 26.1959\n",
      "Epoch 1: val_loss improved from inf to 10.57680, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.4525 - loss: 25.0243 - val_accuracy: 0.8587 - val_loss: 10.5768\n",
      "Epoch 2/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8438 - loss: 12.5140\n",
      "Epoch 2: val_loss improved from 10.57680 to 5.22999, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7473 - loss: 15.8942 - val_accuracy: 0.8587 - val_loss: 5.2300\n",
      "Epoch 3/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7188 - loss: 14.9207\n",
      "Epoch 3: val_loss improved from 5.22999 to 3.21582, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6317 - loss: 13.5161 - val_accuracy: 0.8587 - val_loss: 3.2158\n",
      "Epoch 4/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5312 - loss: 17.5881\n",
      "Epoch 4: val_loss improved from 3.21582 to 3.14680, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6353 - loss: 11.5345 - val_accuracy: 0.8587 - val_loss: 3.1468\n",
      "Epoch 5/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6875 - loss: 8.2522\n",
      "Epoch 5: val_loss improved from 3.14680 to 2.54710, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6889 - loss: 8.2433 - val_accuracy: 0.8587 - val_loss: 2.5471\n",
      "Epoch 6/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5938 - loss: 16.2588\n",
      "Epoch 6: val_loss improved from 2.54710 to 1.45361, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6887 - loss: 8.1568 - val_accuracy: 0.8587 - val_loss: 1.4536\n",
      "Epoch 7/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6875 - loss: 10.0225\n",
      "Epoch 7: val_loss improved from 1.45361 to 1.03950, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6575 - loss: 6.2644 - val_accuracy: 0.8587 - val_loss: 1.0395\n",
      "Epoch 8/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7188 - loss: 4.0910\n",
      "Epoch 8: val_loss improved from 1.03950 to 1.02980, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6974 - loss: 4.3015 - val_accuracy: 0.8587 - val_loss: 1.0298\n",
      "Epoch 9/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5625 - loss: 6.5400\n",
      "Epoch 9: val_loss improved from 1.02980 to 0.93425, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6440 - loss: 5.1514 - val_accuracy: 0.8587 - val_loss: 0.9343\n",
      "Epoch 10/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5312 - loss: 6.2572\n",
      "Epoch 10: val_loss improved from 0.93425 to 0.87842, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6277 - loss: 4.1562 - val_accuracy: 0.8587 - val_loss: 0.8784\n",
      "Epoch 11/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6875 - loss: 2.5062\n",
      "Epoch 11: val_loss improved from 0.87842 to 0.83515, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6911 - loss: 2.9885 - val_accuracy: 0.8587 - val_loss: 0.8352\n",
      "Epoch 12/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7188 - loss: 2.0050\n",
      "Epoch 12: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7090 - loss: 3.1073 - val_accuracy: 0.8587 - val_loss: 0.8946\n",
      "Epoch 13/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9062 - loss: 2.1752\n",
      "Epoch 13: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6894 - loss: 2.8065 - val_accuracy: 0.8370 - val_loss: 1.0052\n",
      "Epoch 14/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6875 - loss: 2.0136\n",
      "Epoch 14: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6714 - loss: 2.2532 - val_accuracy: 0.8587 - val_loss: 1.0214\n",
      "Epoch 15/100\n",
      "\u001b[1m 9/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6666 - loss: 2.4691  \n",
      "Epoch 15: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6612 - loss: 2.5637 - val_accuracy: 0.8587 - val_loss: 1.0800\n",
      "Epoch 16/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.5625 - loss: 2.4645\n",
      "Epoch 16: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6710 - loss: 2.1617 - val_accuracy: 0.8587 - val_loss: 1.0901\n",
      "Epoch 17/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8750 - loss: 4.3207\n",
      "Epoch 17: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7353 - loss: 2.8780 - val_accuracy: 0.8587 - val_loss: 1.1805\n",
      "Epoch 18/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7188 - loss: 1.0605\n",
      "Epoch 18: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6884 - loss: 2.3166 - val_accuracy: 0.8370 - val_loss: 1.2885\n",
      "Epoch 19/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8438 - loss: 1.0328\n",
      "Epoch 19: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7304 - loss: 1.7641 - val_accuracy: 0.8261 - val_loss: 1.2638\n",
      "Epoch 20/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8125 - loss: 1.2705\n",
      "Epoch 20: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7131 - loss: 1.8134 - val_accuracy: 0.8478 - val_loss: 1.2039\n",
      "Epoch 21/100\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7174 - loss: 1.8755 \n",
      "Epoch 21: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7137 - loss: 1.8771 - val_accuracy: 0.8478 - val_loss: 1.2260\n",
      "Epoch 22/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6875 - loss: 2.0288\n",
      "Epoch 22: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7090 - loss: 1.8298 - val_accuracy: 0.8587 - val_loss: 1.3026\n",
      "Epoch 23/100\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7168 - loss: 1.6518 \n",
      "Epoch 23: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7122 - loss: 1.6367 - val_accuracy: 0.8587 - val_loss: 1.3463\n",
      "Epoch 24/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6250 - loss: 2.0415\n",
      "Epoch 24: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7125 - loss: 1.4964 - val_accuracy: 0.8587 - val_loss: 1.3708\n",
      "Epoch 25/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5312 - loss: 1.5353\n",
      "Epoch 25: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6476 - loss: 1.7495 - val_accuracy: 0.8587 - val_loss: 1.3777\n",
      "Epoch 26/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6250 - loss: 2.0638\n",
      "Epoch 26: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6767 - loss: 1.6863 - val_accuracy: 0.8587 - val_loss: 1.3662\n",
      "Epoch 27/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7812 - loss: 1.0466\n",
      "Epoch 27: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7517 - loss: 1.2343 - val_accuracy: 0.8587 - val_loss: 1.3233\n",
      "Epoch 28/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.7188 - loss: 1.2348\n",
      "Epoch 28: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7186 - loss: 1.6032 - val_accuracy: 0.8587 - val_loss: 1.2939\n",
      "Epoch 29/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7188 - loss: 1.1670\n",
      "Epoch 29: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7492 - loss: 1.2869 - val_accuracy: 0.8587 - val_loss: 1.2686\n",
      "Epoch 30/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6562 - loss: 1.3755\n",
      "Epoch 30: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7119 - loss: 1.1851 - val_accuracy: 0.8587 - val_loss: 1.1966\n",
      "Epoch 31/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7812 - loss: 0.9063\n",
      "Epoch 31: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7213 - loss: 1.3830 - val_accuracy: 0.8587 - val_loss: 1.1864\n",
      "Epoch 32/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7188 - loss: 1.6741\n",
      "Epoch 32: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7202 - loss: 1.2901 - val_accuracy: 0.8587 - val_loss: 1.1816\n",
      "Epoch 33/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5938 - loss: 1.9235\n",
      "Epoch 33: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7096 - loss: 1.3165 - val_accuracy: 0.8587 - val_loss: 1.1408\n",
      "Epoch 34/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5938 - loss: 1.6018\n",
      "Epoch 34: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7447 - loss: 1.1247 - val_accuracy: 0.8587 - val_loss: 1.1085\n",
      "Epoch 35/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8438 - loss: 0.7540\n",
      "Epoch 35: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7813 - loss: 1.2268 - val_accuracy: 0.8587 - val_loss: 1.1269\n",
      "Epoch 36/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6875 - loss: 1.3189\n",
      "Epoch 36: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7384 - loss: 1.1840 - val_accuracy: 0.8587 - val_loss: 1.1284\n",
      "Epoch 37/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8438 - loss: 0.7470\n",
      "Epoch 37: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7824 - loss: 0.9327 - val_accuracy: 0.8587 - val_loss: 1.0934\n",
      "Epoch 38/100\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7846 - loss: 1.1196  \n",
      "Epoch 38: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7840 - loss: 1.1181 - val_accuracy: 0.8587 - val_loss: 1.0908\n",
      "Epoch 39/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6875 - loss: 1.1500\n",
      "Epoch 39: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7582 - loss: 1.0414 - val_accuracy: 0.8587 - val_loss: 1.0985\n",
      "Epoch 40/100\n",
      "\u001b[1m 9/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7547 - loss: 1.1090  \n",
      "Epoch 40: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7613 - loss: 1.0830 - val_accuracy: 0.8587 - val_loss: 1.1107\n",
      "Epoch 41/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7812 - loss: 1.1746\n",
      "Epoch 41: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7724 - loss: 1.0940 - val_accuracy: 0.8587 - val_loss: 1.1039\n",
      "Epoch 42/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8125 - loss: 0.8028\n",
      "Epoch 42: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7784 - loss: 1.0625 - val_accuracy: 0.8587 - val_loss: 1.0970\n",
      "Epoch 43/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7188 - loss: 0.9461\n",
      "Epoch 43: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7973 - loss: 1.0206 - val_accuracy: 0.8587 - val_loss: 1.0898\n",
      "Epoch 44/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8750 - loss: 0.8492\n",
      "Epoch 44: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8167 - loss: 0.9492 - val_accuracy: 0.8587 - val_loss: 1.0775\n",
      "Epoch 45/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9062 - loss: 0.6644\n",
      "Epoch 45: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8188 - loss: 0.8937 - val_accuracy: 0.8587 - val_loss: 1.0371\n",
      "Epoch 46/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.8125 - loss: 0.7350\n",
      "Epoch 46: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7874 - loss: 0.9868 - val_accuracy: 0.8587 - val_loss: 1.0138\n",
      "Epoch 47/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9062 - loss: 0.6169\n",
      "Epoch 47: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7873 - loss: 0.9077 - val_accuracy: 0.8587 - val_loss: 1.0053\n",
      "Epoch 48/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8125 - loss: 0.9252\n",
      "Epoch 48: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8037 - loss: 1.0169 - val_accuracy: 0.8587 - val_loss: 1.0202\n",
      "Epoch 49/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8750 - loss: 0.5453\n",
      "Epoch 49: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8140 - loss: 0.7903 - val_accuracy: 0.8587 - val_loss: 0.9813\n",
      "Epoch 50/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8125 - loss: 0.9609\n",
      "Epoch 50: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8136 - loss: 0.8787 - val_accuracy: 0.8587 - val_loss: 0.9397\n",
      "Epoch 51/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8125 - loss: 1.3471\n",
      "Epoch 51: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7931 - loss: 1.0853 - val_accuracy: 0.8587 - val_loss: 0.8849\n",
      "Epoch 52/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8125 - loss: 0.6558\n",
      "Epoch 52: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8198 - loss: 0.8785 - val_accuracy: 0.8587 - val_loss: 0.8997\n",
      "Epoch 53/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7500 - loss: 1.1332\n",
      "Epoch 53: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7969 - loss: 0.9567 - val_accuracy: 0.8587 - val_loss: 0.9531\n",
      "Epoch 54/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 1.3766\n",
      "Epoch 54: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8111 - loss: 0.9749 - val_accuracy: 0.8587 - val_loss: 0.9433\n",
      "Epoch 55/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7812 - loss: 1.0421\n",
      "Epoch 55: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7975 - loss: 0.9589 - val_accuracy: 0.8587 - val_loss: 0.9179\n",
      "Epoch 56/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8438 - loss: 0.7880\n",
      "Epoch 56: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7961 - loss: 0.9377 - val_accuracy: 0.8587 - val_loss: 0.9166\n",
      "Epoch 57/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7188 - loss: 1.0400\n",
      "Epoch 57: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7916 - loss: 0.9812 - val_accuracy: 0.8587 - val_loss: 0.9277\n",
      "Epoch 58/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9062 - loss: 0.4746\n",
      "Epoch 58: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8156 - loss: 0.8120 - val_accuracy: 0.8587 - val_loss: 0.9061\n",
      "Epoch 59/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9062 - loss: 0.6523\n",
      "Epoch 59: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8448 - loss: 0.7685 - val_accuracy: 0.8587 - val_loss: 0.8877\n",
      "Epoch 60/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8750 - loss: 0.6989\n",
      "Epoch 60: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8249 - loss: 0.8172 - val_accuracy: 0.8587 - val_loss: 0.9027\n",
      "Epoch 61/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6875 - loss: 1.6333\n",
      "Epoch 61: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8036 - loss: 0.9974 - val_accuracy: 0.8587 - val_loss: 0.9182\n",
      "Epoch 62/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8750 - loss: 0.6089\n",
      "Epoch 62: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8407 - loss: 0.7713 - val_accuracy: 0.8587 - val_loss: 0.8949\n",
      "Epoch 63/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8125 - loss: 0.9904\n",
      "Epoch 63: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8188 - loss: 0.9338 - val_accuracy: 0.8587 - val_loss: 0.9071\n",
      "Epoch 64/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8438 - loss: 0.8563\n",
      "Epoch 64: val_loss did not improve from 0.83515\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8412 - loss: 0.7943 - val_accuracy: 0.8587 - val_loss: 0.8727\n",
      "Epoch 65/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8750 - loss: 0.5361\n",
      "Epoch 65: val_loss improved from 0.83515 to 0.82327, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8311 - loss: 0.8411 - val_accuracy: 0.8587 - val_loss: 0.8233\n",
      "Epoch 66/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8438 - loss: 0.6646\n",
      "Epoch 66: val_loss did not improve from 0.82327\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8323 - loss: 0.8310 - val_accuracy: 0.8587 - val_loss: 0.8302\n",
      "Epoch 67/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.8125 - loss: 1.2178\n",
      "Epoch 67: val_loss did not improve from 0.82327\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8039 - loss: 1.0118 - val_accuracy: 0.8587 - val_loss: 0.8331\n",
      "Epoch 68/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6562 - loss: 1.1687\n",
      "Epoch 68: val_loss improved from 0.82327 to 0.81128, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8192 - loss: 0.8506 - val_accuracy: 0.8587 - val_loss: 0.8113\n",
      "Epoch 69/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7500 - loss: 1.2023\n",
      "Epoch 69: val_loss did not improve from 0.81128\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8106 - loss: 0.8582 - val_accuracy: 0.8587 - val_loss: 0.8120\n",
      "Epoch 70/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.8125 - loss: 0.8918\n",
      "Epoch 70: val_loss did not improve from 0.81128\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8134 - loss: 0.8323 - val_accuracy: 0.8587 - val_loss: 0.8265\n",
      "Epoch 71/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.8125 - loss: 0.9792\n",
      "Epoch 71: val_loss improved from 0.81128 to 0.80201, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8267 - loss: 0.8116 - val_accuracy: 0.8587 - val_loss: 0.8020\n",
      "Epoch 72/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8125 - loss: 0.9671\n",
      "Epoch 72: val_loss did not improve from 0.80201\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8167 - loss: 0.8541 - val_accuracy: 0.8587 - val_loss: 0.8053\n",
      "Epoch 73/100\n",
      "\u001b[1m 8/12\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8074 - loss: 0.8410  \n",
      "Epoch 73: val_loss did not improve from 0.80201\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8148 - loss: 0.8281 - val_accuracy: 0.8587 - val_loss: 0.8035\n",
      "Epoch 74/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6875 - loss: 1.3332\n",
      "Epoch 74: val_loss did not improve from 0.80201\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7878 - loss: 0.9665 - val_accuracy: 0.8587 - val_loss: 0.8180\n",
      "Epoch 75/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7500 - loss: 1.0173\n",
      "Epoch 75: val_loss did not improve from 0.80201\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8040 - loss: 0.8001 - val_accuracy: 0.8587 - val_loss: 0.8063\n",
      "Epoch 76/100\n",
      "\u001b[1m 7/12\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7890 - loss: 0.9959 \n",
      "Epoch 76: val_loss improved from 0.80201 to 0.79701, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8063 - loss: 0.9298 - val_accuracy: 0.8587 - val_loss: 0.7970\n",
      "Epoch 77/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8438 - loss: 0.7112\n",
      "Epoch 77: val_loss did not improve from 0.79701\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8262 - loss: 0.8728 - val_accuracy: 0.8587 - val_loss: 0.7982\n",
      "Epoch 78/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8750 - loss: 0.8319\n",
      "Epoch 78: val_loss improved from 0.79701 to 0.78828, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8335 - loss: 0.7890 - val_accuracy: 0.8587 - val_loss: 0.7883\n",
      "Epoch 79/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8438 - loss: 0.7436\n",
      "Epoch 79: val_loss did not improve from 0.78828\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8287 - loss: 0.8777 - val_accuracy: 0.8587 - val_loss: 0.7960\n",
      "Epoch 80/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9062 - loss: 0.6676\n",
      "Epoch 80: val_loss did not improve from 0.78828\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8336 - loss: 0.8209 - val_accuracy: 0.8587 - val_loss: 0.8077\n",
      "Epoch 81/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8125 - loss: 0.8579\n",
      "Epoch 81: val_loss did not improve from 0.78828\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8064 - loss: 0.8200 - val_accuracy: 0.8587 - val_loss: 0.8183\n",
      "Epoch 82/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 0.7500 - loss: 1.1271\n",
      "Epoch 82: val_loss did not improve from 0.78828\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8007 - loss: 0.9130 - val_accuracy: 0.8587 - val_loss: 0.8060\n",
      "Epoch 83/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7500 - loss: 1.4728\n",
      "Epoch 83: val_loss improved from 0.78828 to 0.77539, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8209 - loss: 0.8831 - val_accuracy: 0.8587 - val_loss: 0.7754\n",
      "Epoch 84/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8750 - loss: 0.7239\n",
      "Epoch 84: val_loss improved from 0.77539 to 0.76006, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8324 - loss: 0.7231 - val_accuracy: 0.8587 - val_loss: 0.7601\n",
      "Epoch 85/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8750 - loss: 0.5485\n",
      "Epoch 85: val_loss did not improve from 0.76006\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8308 - loss: 0.7740 - val_accuracy: 0.8587 - val_loss: 0.7778\n",
      "Epoch 86/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8438 - loss: 0.8587\n",
      "Epoch 86: val_loss did not improve from 0.76006\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8242 - loss: 0.7985 - val_accuracy: 0.8587 - val_loss: 0.8081\n",
      "Epoch 87/100\n",
      "\u001b[1m 9/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8190 - loss: 0.8029 \n",
      "Epoch 87: val_loss did not improve from 0.76006\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8215 - loss: 0.7965 - val_accuracy: 0.8587 - val_loss: 0.7908\n",
      "Epoch 88/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9062 - loss: 0.5276\n",
      "Epoch 88: val_loss did not improve from 0.76006\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8268 - loss: 0.7802 - val_accuracy: 0.8587 - val_loss: 0.7819\n",
      "Epoch 89/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8750 - loss: 0.5649\n",
      "Epoch 89: val_loss improved from 0.76006 to 0.76003, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8321 - loss: 0.7803 - val_accuracy: 0.8587 - val_loss: 0.7600\n",
      "Epoch 90/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8438 - loss: 0.7683\n",
      "Epoch 90: val_loss improved from 0.76003 to 0.75371, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8078 - loss: 0.8379 - val_accuracy: 0.8587 - val_loss: 0.7537\n",
      "Epoch 91/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7812 - loss: 0.7331\n",
      "Epoch 91: val_loss improved from 0.75371 to 0.74723, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8144 - loss: 0.7517 - val_accuracy: 0.8587 - val_loss: 0.7472\n",
      "Epoch 92/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9375 - loss: 0.4874\n",
      "Epoch 92: val_loss improved from 0.74723 to 0.74138, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8448 - loss: 0.7199 - val_accuracy: 0.8587 - val_loss: 0.7414\n",
      "Epoch 93/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8750 - loss: 0.6566\n",
      "Epoch 93: val_loss did not improve from 0.74138\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8309 - loss: 0.7986 - val_accuracy: 0.8587 - val_loss: 0.7477\n",
      "Epoch 94/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7812 - loss: 0.9553\n",
      "Epoch 94: val_loss did not improve from 0.74138\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8370 - loss: 0.7507 - val_accuracy: 0.8587 - val_loss: 0.7511\n",
      "Epoch 95/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8438 - loss: 0.6403\n",
      "Epoch 95: val_loss did not improve from 0.74138\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8397 - loss: 0.7183 - val_accuracy: 0.8587 - val_loss: 0.7424\n",
      "Epoch 96/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9375 - loss: 0.6155\n",
      "Epoch 96: val_loss improved from 0.74138 to 0.73117, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8506 - loss: 0.7172 - val_accuracy: 0.8587 - val_loss: 0.7312\n",
      "Epoch 97/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8750 - loss: 0.7346\n",
      "Epoch 97: val_loss did not improve from 0.73117\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8339 - loss: 0.7974 - val_accuracy: 0.8587 - val_loss: 0.7414\n",
      "Epoch 98/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.6875 - loss: 1.0126\n",
      "Epoch 98: val_loss did not improve from 0.73117\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8017 - loss: 0.7919 - val_accuracy: 0.8587 - val_loss: 0.7361\n",
      "Epoch 99/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7812 - loss: 0.9092\n",
      "Epoch 99: val_loss did not improve from 0.73117\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8385 - loss: 0.7465 - val_accuracy: 0.8587 - val_loss: 0.7351\n",
      "Epoch 100/100\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8438 - loss: 0.7207\n",
      "Epoch 100: val_loss did not improve from 0.73117\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8238 - loss: 0.7995 - val_accuracy: 0.8587 - val_loss: 0.7405\n",
      "Training completed in time:  0:00:17.887156\n"
     ]
    }
   ],
   "source": [
    "## Trianing my model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.keras', \n",
    "                               verbose=1, save_best_only=True)\n",
    "# Save the model\n",
    "model.save('saved_models/audio_classification.keras')\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0c15dcd2-f080-4c46-901b-f36c1c439d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8586956262588501\n"
     ]
    }
   ],
   "source": [
    "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "7a5eb6d2-55d0-4b17-b111-cde9cca50127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-410.85556 ,   46.24001 ,  -10.46998 ,   -5.892804,  -15.497193,\n",
       "        -11.711424,  -23.498938,  -12.768632,  -13.778734,   -6.802423,\n",
       "        -14.231   ,  -14.329665,  -16.73    ], dtype=float32)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "a617b7ff-f92d-410b-95c7-1d0bfe5e3388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictions = model.predict(X_test)\n",
    "# Convert probabilities to class labels\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "print(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdd2571-e3b9-4282-a0e4-6bec3f2e4661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e8fcba11-d9ad-4353-bf3c-4d3ea1d85eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the path of the audio file:  C:\\Users\\HP\\Desktop\\baby_crying\\donateacry_corpus_cleaned_and_updated_data\\belly_pain\\ae5f103b-5fee-442f-bb1b-d9d0570c46ab-1431533857965-1.7-m-26-bp.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Predicted class: hungry\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def load_label_encoder(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        classes = pickle.load(file)\n",
    "    labelencoder = LabelEncoder()\n",
    "    labelencoder.classes_ = classes\n",
    "    return labelencoder\n",
    "\n",
    "def preprocess_audio(filename):\n",
    "    y, sr = librosa.load(filename, sr=None)\n",
    "    mfccs_features = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T, axis=0)\n",
    "    return mfccs_scaled_features.reshape(1, -1)\n",
    "\n",
    "def predict_audio_class(filename, model, labelencoder):\n",
    "    features = preprocess_audio(filename)\n",
    "    predicted_probabilities = model.predict(features)\n",
    "    predicted_label = np.argmax(predicted_probabilities, axis=1)\n",
    "    prediction_class = labelencoder.inverse_transform(predicted_label)\n",
    "    return prediction_class[0]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the trained model\n",
    "    model = tf.keras.models.load_model('saved_models/audio_classification.keras')\n",
    "\n",
    "    # Load the label encoder\n",
    "    labelencoder = load_label_encoder('label_classes.pkl')\n",
    "\n",
    "    # Take user input for the audio file path\n",
    "    filename = input(\"Enter the path of the audio file: \")\n",
    "    \n",
    "    # Predict the class of the audio file\n",
    "    predicted_class = predict_audio_class(filename, model, labelencoder)\n",
    "    print(\"Predicted class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "19cc4de2-ab69-4e1e-a2ac-cb4b93485a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCCs scaled features: [-303.28653     57.470528    -3.8972733   -3.6200895  -22.772476\n",
      "    2.9935045  -11.351922   -14.612647   -28.033195    -2.375577\n",
      "  -10.980385     5.6036487    1.424868 ]\n",
      "Reshaped MFCCs scaled features: [[-303.28653     57.470528    -3.8972733   -3.6200895  -22.772476\n",
      "     2.9935045  -11.351922   -14.612647   -28.033195    -2.375577\n",
      "   -10.980385     5.6036487    1.424868 ]]\n",
      "Shape of MFCCs scaled features: (1, 13)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "Predicted label (encoded): [3]\n",
      "Predicted class (decoded): ['hungry']\n"
     ]
    }
   ],
   "source": [
    "# filename = r\"C:\\Users\\HP\\Desktop\\baby_crying\\donateacry_corpus_cleaned_and_updated_data\\belly_pain\\ae5f103b-5fee-442f-bb1b-d9d0570c46ab-1431533857965-1.7-m-26-bp.wav\"\n",
    "# y, sr = librosa.load(filename, sr=None)\n",
    "# mfccs_features = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "# mfccs_scaled_features = np.mean(mfccs_features.T, axis=0)\n",
    "\n",
    "# print(\"MFCCs scaled features:\", mfccs_scaled_features)\n",
    "# mfccs_scaled_features = mfccs_scaled_features.reshape(1, -1)\n",
    "# print(\"Reshaped MFCCs scaled features:\", mfccs_scaled_features)\n",
    "# print(\"Shape of MFCCs scaled features:\", mfccs_scaled_features.shape)\n",
    "\n",
    "# # Load your trained model\n",
    "# model = tf.keras.models.load_model('saved_models/audio_classification.keras')\n",
    "\n",
    "# # Make predictions\n",
    "# predicted_probabilities = model.predict(mfccs_scaled_features)\n",
    "# predicted_label = np.argmax(predicted_probabilities, axis=1)\n",
    "# print(\"Predicted label (encoded):\", predicted_label)\n",
    "\n",
    "# # Load your label encoder\n",
    "# labelencoder = LabelEncoder()\n",
    "# labelencoder.classes_ = np.load('label_classes.npy')\n",
    "\n",
    "# # Decode the predicted label to get the class name\n",
    "# prediction_class = labelencoder.inverse_transform(predicted_label)\n",
    "# print(\"Predicted class (decoded):\", prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63f1080-296c-4254-b57d-361b0bc67f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved_models/audio_classification.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "13784999-53a2-4f60-b171-8905823f281d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # label_classes.npy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf2f3a0-63eb-4ef9-a28d-211b3375fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a5dd47-ea78-480c-a7b5-7e2b7c5e86d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
